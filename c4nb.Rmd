---
title: "Flitering mobile phone spam with Naive Bayes"
date: "`r Sys.time()`"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data

SMS spam data
```{r}
sms_raw = read.csv("sms_spam.csv", stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type = factor(sms_raw$type)
str(sms_raw$type)
table(sms_raw$type)
```

## Data preperation and data cleaning
Handling this type of data takes a lot of thought and effort. One need to consider how to remove numbers and punctuation; handle uninteresting words such as and, but, and or; and how to break apart sentences into individual words.
```{r}
if(!require(tm)) {install.packages("tm")}
library(tm)
sms_corpus = VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
```

Change into lowercase:
```{r}
sms_corpus_clean = tm_map(sms_corpus, content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
```

Remove numbers, punctuations:
```{r}
sms_corpus_clean = tm_map(sms_corpus_clean, removeNumbers)
sms_corpus_clean = tm_map(sms_corpus_clean, removeWords, stopwords())
sms_corpus_clean = tm_map(sms_corpus_clean, removePunctuation)
```

Reduce words into stemmign. The stemming process takes words like learned, learning, and learns into the base form, learn.
```{r}
if(!require(SnowballC)) {install.packages("SnowballC")}
library(SnowballC)
sms_corpus_clean = tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean = tm_map(sms_corpus_clean, stripWhitespace)
as.character(sms_corpus[[3]])
as.character(sms_corpus_clean[[3]])
```

Splitting text document, creating a Document Team Matrix (DTM) sparse matrix:
```{r}
sms_dtm = DocumentTermMatrix(sms_corpus_clean)
sms_dtm2 = DocumentTermMatrix(sms_corpus, control = list(tolower = TRUE, removeNumbers = TRUE, stopwords = TRUE, removePunctuation = TRUE, stemming = TRUE))
sms_dtm
sms_dtm2
```

## Creating training and testing data
75 percent training and 25 percent testing
```{r}
sms_dtm_train = sms_dtm[1:4169, ]
sms_dtm_test  = sms_dtm[4170:5559, ]
sms_train_labels = sms_raw[1:4169, ]$type
sms_test_labels  = sms_raw[4170:5559, ]$type
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
```

## Visualization
```{r}
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
```

Subest data visualization
```{r}
spam = subset(sms_raw, type == "spam")
ham  = subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
```

Creating indicator features for frequent words
```{r}
sms_freq_word = findFreqTerms(sms_dtm_train, 5)
str(sms_freq_word)
```

Filter the DTM with the specified vector:
```{r}
sms_dtm_freq_train = sms_dtm_train[, sms_freq_word]
sms_dtm_freq_test  = sms_dtm_test[, sms_freq_word]

convert_counts = function(x) {
  x = ifelse(x > 0, "Yes", "No")
}
sms_train = apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  = apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
```

## Model
Build classifier and make prediction.
```{r}
if (!require(e1071)) {install.packages("e1071")}
library(e1071)
sms_classifier  = naiveBayes(sms_train, sms_train_labels)
sms_predictions = predict(sms_classifier, sms_test)

library(gmodels)
CrossTable(sms_predictions, sms_test_labels, prop.chisq = FALSE, prop.t = FALSE, dnn = c("predict", "actual"))
```

Improve the performance
```{r}
sms_classifier2 = naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_predictions2 = predict(sms_classifier2, sms_test)
CrossTable(sms_predictions2, sms_test_labels, prop.chisq = FALSE, prop.t = FALSE, dnn = c("predicted", "actual"))
```






